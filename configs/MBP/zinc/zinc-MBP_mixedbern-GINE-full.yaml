out_dir: results
metric_best: mae
metric_agg: argmin
num_workers: 4
tensorboard_each_run: False  # Log to Tensorboard each run
accelerator: "cuda:0"
wandb:
  use: False
  project: ZINC
dataset:
  format: PyG-ZINC
  name: subset
  task: graph
  task_type: regression
  transductive: False
  node_encoder: True
  node_encoder_name: TypeDictNode
  node_encoder_num_types: 21  # actually 21 in Zinc-12k, 28 in Zinc-full
  node_encoder_bn: False
  edge_encoder: True
  edge_encoder_name: TypeDictEdge
  edge_encoder_num_types: 4
  edge_encoder_bn: False
posenc_Poly:
  enable: True
  add_full_edge_index: True
  method: mixed_bern
  power: 6
train:
  mode: custom
  batch_size: 32
  eval_period: 1
  enable_ckpt: False  # Checkpointing can now be disabled to save I/O when e.g. just benchmarking.
  ckpt_best: False  # WARNING: Checkpoint every epoch a better model is found may increase I/O significantly.
  ckpt_clean: True # Delete old ckpt each time.
  ckpt_period: 500
model:
  type: MbpModel
  loss_fun: l1
  edge_decoding: dot
  graph_pooling: add
mbp_model:
  enable: True
  hidden_dim: 96
  attn_heads: 8
  drop_prob: 0.0
  attn_drop_prob: 0.2
  residual: True
  layer_norm: False
  batch_norm: True
  bn_momentum: 0.1
  bn_no_runner: False
  rezero: False
  deg_scaler: True
  clamp: 5.0
  weight_fn: softmax
  agg: add
  act: relu
  messaging:
    layer_type: gine
    num_blocks: 0
    repeats: 0
  full:
    layer_type: gine
    enable: True
    repeats: 10
    input_norm: False
gnn:
  head: san_graph
optim:
  clip_grad_norm: True
  optimizer: adamW
  weight_decay: 1e-5
  base_lr: 1e-3
  max_epoch: 2000
  num_warmup_epochs: 50
  scheduler: cosine_with_warmup
  min_lr: 1e-6
