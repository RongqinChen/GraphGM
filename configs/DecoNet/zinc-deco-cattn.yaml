out_dir: results
metric_best: mae
metric_agg: argmin
num_workers: 4
wandb:
  use: False
  project: ZINC
dataset:
  format: PyG-ZINC
  name: subset
  task: graph
  task_type: regression
  transductive: False
  node_encoder: True
  node_encoder_name: TypeDictNode
  node_encoder_num_types: 21  # actually 21 in Zinc-12k, 28 in Zinc-full
  node_encoder_bn: False
  edge_encoder: True
  edge_encoder_name: TypeDictEdge
  edge_encoder_num_types: 4
  edge_encoder_bn: False
posenc_Poly:
  enable: True
  add_full_edge_index: True
  method: deconet_bern
  power: 8
train:
  mode: custom
  batch_size: 32
  eval_period: 1
  enable_ckpt: False  # Checkpointing can now be disabled to save I/O when e.g. just benchmarking.
  ckpt_best: False  # WARNING: Checkpoint every epoch a better model is found may increase I/O significantly.
  ckpt_clean: True # Delete old ckpt each time.
  ckpt_period: 500
model:
  type: DecoNet
  loss_fun: l1
  graph_pooling: mean
DecoNet:
  conv:
    num_layers: 5
    k1_hidden_dim: 64
    hidden_dim: 64
    bias: True
    batch_norm: True
    act: gelu
    drop_prob: 0.0
  gblock:
    layer_type: conditional
    num_layers: 5
    hidden_dim: 64
    attn_heads: 8
    clamp: 5
    attn_drop_prob: 0.2
    drop_prob: 0.0
    weight_fn: softmax
    agg: add
    act: gelu
    bn_momentum: 0.1
  pe_layer: simple_linear
gnn:
  head: san_graph
  layers_post_mp: 2
optim:
  clip_grad_norm: True
  optimizer: adamW
  weight_decay: 0.0
  base_lr: 1e-3
  max_epoch: 2000
  num_warmup_epochs: 50
  scheduler: cosine_with_warmup
  min_lr: 1e-6
